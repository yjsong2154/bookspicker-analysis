import os
import sys
import random
import json
import time
from dotenv import load_dotenv

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules import converter, splitter, tagger

def main():
    # 1. í™˜ê²½ ì„¤ì •
    load_dotenv() # .env íŒŒì¼ ë¡œë“œ (í˜„ì¬ ë””ë ‰í† ë¦¬ ë˜ëŠ” ìƒìœ„ ë””ë ‰í† ë¦¬ íƒìƒ‰)
    
    if not os.getenv("GMS_KEY"):
        print("âš ï¸  Warning: GMS_KEY not found in environment variables. Tagging might fail.")
        print("Please ensure .env file exists in this directory or parent directory.")

    base_dir = os.path.dirname(os.path.abspath(__file__))
    input_dir = os.path.join(base_dir, "input")
    output_dir = os.path.join(base_dir, "output")
    
    txt_output_dir = os.path.join(output_dir, "txt")
    chunks_output_dir = os.path.join(output_dir, "chunks")
    tags_output_dir = os.path.join(output_dir, "tags")

    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(input_dir, exist_ok=True)
    os.makedirs(txt_output_dir, exist_ok=True)
    os.makedirs(chunks_output_dir, exist_ok=True)
    os.makedirs(tags_output_dir, exist_ok=True)

    # 2. EPUB íŒŒì¼ ëª©ë¡ ìŠ¤ìº”
    epub_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.epub')]
    
    if not epub_files:
        print(f"â„¹ï¸  No .epub files found in {input_dir}")
        print("Please place .epub files in the 'input' directory and run again.")
        return

    print(f"ğŸ“š Found {len(epub_files)} epub files. Starting processing...")

    for epub_file in epub_files:
        print(f"\nğŸš€ Processing: {epub_file}")
        file_name_no_ext = os.path.splitext(epub_file)[0]
        epub_path = os.path.join(input_dir, epub_file)
        
        # --- Step 1: EPUB to TXT ---
        txt_filename = f"{file_name_no_ext}_text.txt"
        txt_path = os.path.join(txt_output_dir, txt_filename)
        
        print(f"  [1/3] Converting to TXT: {txt_filename}")
        try:
            converter.convert_epub_to_txt(epub_path, txt_path)
        except Exception as e:
            print(f"  âŒ Failed to convert {epub_file}: {e}")
            continue

        # --- Step 2: TXT to Chunks ---
        print(f"  [2/3] Splitting into Chunks...")
        try:
            with open(txt_path, 'r', encoding='utf-8') as f:
                text_content = f.read()
            
            chunks = splitter.split_into_chunks(text_content)
            
            # ì²­í¬ ì €ì¥ í´ë”: (ì›ë˜ì œëª©)_chunks
            book_chunks_dir = os.path.join(chunks_output_dir, f"{file_name_no_ext}_chunks")
            # íŒŒì¼ prefix: (ì›ë˜ì œëª©)_chunk
            chunk_prefix = f"{file_name_no_ext}_chunk"
            
            saved_chunk_paths = splitter.save_chunks(chunks, book_chunks_dir, chunk_prefix)
            print(f"    -> Created {len(saved_chunk_paths)} chunks in {book_chunks_dir}")
            
        except Exception as e:
            print(f"  âŒ Failed to split chunks for {epub_file}: {e}")
            continue

        # --- Step 3: Sampling & Tagging ---
        print(f"  [3/3] Sampling and Tagging...")
        
        # íƒœê·¸ ì €ì¥ í´ë”: (ì›ë˜ì œëª©)_tags
        book_tags_dir = os.path.join(tags_output_dir, f"{file_name_no_ext}_tags")
        os.makedirs(book_tags_dir, exist_ok=True)

        # 4ê°œì”© ê·¸ë£¹í•‘í•˜ì—¬ ëœë¤ ì„ íƒ
        # chunks ë¦¬ìŠ¤íŠ¸ëŠ” ì´ë¯¸ ë©”ëª¨ë¦¬ì— ìˆìŒ (chunks ë³€ìˆ˜)
        # í•˜ì§€ë§Œ íŒŒì¼ ê²½ë¡œë¡œ ì‘ì—…í•˜ëŠ” ê²ƒì´ ëª…í™•í•  ìˆ˜ ìˆìœ¼ë‹ˆ saved_chunk_paths ì‚¬ìš© ê°€ëŠ¥
        # ì—¬ê¸°ì„œëŠ” chunks í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì§ì ‘ ì‚¬ìš©
        
        selected_indices = []
        group_size = 4
        
        for i in range(0, len(chunks), group_size):
            group_indices = list(range(i, min(i + group_size, len(chunks))))
            if group_indices:
                selected_idx = random.choice(group_indices)
                selected_indices.append(selected_idx)
        
        print(f"    -> Selected {len(selected_indices)} chunks for tagging (out of {len(chunks)})")
        
        for i, idx in enumerate(selected_indices):
            chunk_text = chunks[idx]
            # íƒœê·¸ íŒŒì¼ëª…: (ì›ë˜ì œëª©)_tag_01.json (ìˆœì°¨ ë²ˆí˜¸)
            tag_filename = f"{file_name_no_ext}_tag_{i+1:02d}.json"
            tag_path = os.path.join(book_tags_dir, tag_filename)
            
            print(f"    -> Tagging chunk {idx+1}/{len(chunks)} as {tag_filename}...", end="", flush=True)
            
            tags = tagger.tag_chunk_with_gpt(chunk_text)
            
            if tags:
                with open(tag_path, 'w', encoding='utf-8') as f:
                    json.dump(tags, f, ensure_ascii=False, indent=2)
                print(" Done.")
            else:
                print(" Failed.")
            
            # API Rate Limit ê³ ë ¤í•˜ì—¬ ì ì‹œ ëŒ€ê¸° (ì„ íƒì‚¬í•­)
            time.sleep(0.5)

    print("\nâœ… All processing completed!")

if __name__ == "__main__":
    main()
